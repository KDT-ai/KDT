{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a56f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # 가중치 초기화\n",
    "        self.W_f = np.random.randn(hidden_size, input_size + hidden_size) * 0.01\n",
    "        self.b_f = np.zeros((hidden_size, 1))\n",
    " \n",
    "        self.W_i = np.random.randn(hidden_size, input_size + hidden_size) * 0.01\n",
    "        self.b_i = np.zeros((hidden_size, 1))\n",
    " \n",
    "        self.W_C = np.random.randn(hidden_size, input_size + hidden_size) * 0.01\n",
    "        self.b_C = np.zeros((hidden_size, 1))\n",
    " \n",
    "        self.W_o = np.random.randn(hidden_size, input_size + hidden_size) * 0.01\n",
    "        self.b_o = np.zeros((hidden_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    " \n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9920bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x_t, h_prev, C_prev):\n",
    "        \"\"\"\n",
    "        LSTM 셀의 순전파 연산 수행\n",
    "        :param x_t: 현재 입력 (shape: input_size)\n",
    "        :param h_prev: 이전 은닉 상태 (shape: hidden_size)\n",
    "        :param C_prev: 이전 셀 상태 (shape: hidden_size)\n",
    "        :return: h_t, C_t (현재 은닉 상태와 셀 상태)\n",
    "        \"\"\"\n",
    "        concat = np.vstack((h_prev, x_t))  # (hidden_size + input_size, 1)\n",
    " \n",
    "        # 망각 게이트\n",
    "        f_t = self.sigmoid(np.dot(self.W_f, concat) + self.b_f)\n",
    "        \n",
    "        # 입력 게이트\n",
    "        i_t = self.sigmoid(np.dot(self.W_i, concat) + self.b_i)\n",
    "        C_tilde = self.tanh(np.dot(self.W_C, concat) + self.b_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # 새로운 셀 상태\n",
    "        C_t = f_t * C_prev + i_t * C_tilde\n",
    "        \n",
    "        # 출력 게이트\n",
    "        o_t = self.sigmoid(np.dot(self.W_o, concat) + self.b_o)\n",
    "        h_t = o_t * self.tanh(C_t)\n",
    " \n",
    "        return h_t, C_t, f_t, i_t, o_t, C_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 차원 및 은닉 상태 차원 정의\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "seq_length = 10  # 시퀀스 길이\n",
    " \n",
    "# LSTM 셀 초기화\n",
    "lstm_cell = LSTMCell(input_size, hidden_size)\n",
    " \n",
    "# 초기 은닉 상태 및 셀 상태\n",
    "h_t = np.zeros((hidden_size, 1))\n",
    "C_t = np.zeros((hidden_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더미 입력 데이터 (랜덤)\n",
    "np.random.seed(0)\n",
    "inputs = [np.random.randn(input_size, 1) for _ in range(seq_length)]\n",
    " \n",
    "# 시퀀스 처리 및 값 저장\n",
    "h_states = []\n",
    "C_states = []\n",
    "forget_gates = []\n",
    "input_gates = []\n",
    "output_gates = []\n",
    "cell_candidates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_t in inputs:\n",
    "    h_t, C_t, f_t, i_t, o_t, C_tilde = lstm_cell.forward(x_t, h_t, C_t)\n",
    "    h_states.append(h_t.flatten())\n",
    "    C_states.append(C_t.flatten())\n",
    "    forget_gates.append(f_t.flatten())\n",
    "    input_gates.append(i_t.flatten())\n",
    "    output_gates.append(o_t.flatten())\n",
    "    cell_candidates.append(C_tilde.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78665871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  애플(AAPL) 주가 데이터 다운로드\n",
    "stock_data = yf.download('AAPL', start='2020-01-01', end='2024-01-01')\n",
    "data = stock_data[['Close']].values\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d911ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 데이터 생성\n",
    "def create_sequences(data, seq_length):\n",
    "   X, y = [], []\n",
    "   for i inrange(len(data) - seq_length):\n",
    "     X.append(data[i:i + seq_length])\n",
    "     y.append(data[i + seq_length])\n",
    "   return np.array(X), np.array(y)\n",
    "seq_length =50\n",
    "X, y = create_sequences(data_scaled, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafefae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련/테스트 데이터 분할\n",
    "train_size =int(len(X) *0.8)\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e48487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 구축\n",
    "model = Sequential([\n",
    "   LSTM(units=50, return_sequences=True, input_shape=(seq_length, 1)),\n",
    "   LSTM(units=50, return_sequences=False),\n",
    "   Dense(units=25, activation='relu'),\n",
    "   Dense(units=1)\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 수행\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_actual, label=\"Actual Price\", color='blue')\n",
    "plt.plot(predictions, label=\"Predicted Price\", color='red')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Apple Stock Price Prediction using LSTM\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 (Alice in Wonderland 텍스트 일부)\n",
    "text = \"\"\"Alice was beginning to get very tired of sitting by her sister on the bank, \n",
    "and of having nothing to do: \n",
    "once or twice she had peeped into the book her sister was reading, \n",
    "but it had no pictures or conversations in it, \n",
    "\"and what is the use of a book,\" \n",
    "thought Alice \"without pictures or conversation?\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    " \n",
    "# 시퀀스 데이터 생성\n",
    "input_sequences = []\n",
    "words = text.split()\n",
    "for i in range(1, len(words)):\n",
    "    n_gram_sequence = words[:i+1]\n",
    "    encoded = tokenizer.texts_to_sequences([\" \".join(n_gram_sequence)])[0]\n",
    "    input_sequences.append(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaeecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 적용\n",
    "max_length = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_length, padding='pre')\n",
    " \n",
    "# X, y 분할\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 구축\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 10, input_length=max_length-1),\n",
    "    LSTM(100),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607264c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성 함수\n",
    "def generate_text(seed_text, next_words=10):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_length-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afde8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성 함수\n",
    "def generate_text(seed_text, next_words=10):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_length-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "# 예제 실행\n",
    "print(generate_text(\"Alice was beginning\", next_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92c0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB 데이터셋 로드\n",
    "num_words = 10000  # 상위 10,000개의 단어만 사용\n",
    "max_length = 200  # 리뷰 길이 제한\n",
    " \n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)\n",
    " \n",
    "# 패딩 적용 (모든 리뷰를 동일한 길이로 맞춤)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 기반 감성 분석 모델 구축\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=32, input_length=max_length),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')  # 긍정(1) / 부정(0) 분류\n",
    "])\n",
    " \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49962ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

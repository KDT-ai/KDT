{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b2ae25c",
   "metadata": {},
   "source": [
    "Vision Transformer 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f2146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001  # 학습률 설정\n",
    "weight_decay = 0.0001  # 가중치 감소(정규화) 값 설정\n",
    "batch_size = 256  # 배치 크기\n",
    "num_epochs = 10  # 학습 반복 횟수 (실제 학습에서는 100을 권장, 10은 테스트 값)\n",
    "image_size = 72  # 입력 이미지 크기를 이 크기로 리사이징\n",
    "patch_size = 6  # 입력 이미지에서 추출할 패치 크기\n",
    "num_patches = (image_size // patch_size) ** 2  # 총 패치 개수\n",
    "projection_dim = 64  # 패치 임베딩 차원 크기\n",
    "num_heads = 4  # 멀티헤드 어텐션에서 사용할 헤드 개수\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Transformer 레이어 크기\n",
    "transformer_layers = 8  # Transformer 블록 개수\n",
    "mlp_head_units = \n",
    "[2048,1024,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),  # 데이터 정규화 (평균 및 분산을 이용해 스케일 조정)\n",
    "        layers.Resizing(image_size, image_size),  # 이미지 크기를 지정된 크기(image_size)로 조정\n",
    "        layers.RandomFlip(\"horizontal\"),  # 이미지를 좌우로 무작위 반전 (데이터 증강)\n",
    "        layers.RandomRotation(factor=0.02),  # 이미지를 약간 회전 (최대 2% 범위)\n",
    "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),  # 랜덤 줌 (높이와 너비 20%까지 확대/축소)\n",
    "    ],\n",
    "    name=\"data_augmentation\",  # 데이터 증강 레이어의 이름 설정\n",
    ")\n",
    "# 정규화를 위해 훈련 데이터의 평균과 분산을 계산\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=keras.activations.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):  # 패치(Patch) 추출을 위한 커스텀 Keras 레이어\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size  # 패치 크기 저장\n",
    "    def call(self, images):  # 입력 이미지에서 패치를 추출하는 함수\n",
    "        input_shape = ops.shape(images)  # 입력 이미지의 크기 가져오기\n",
    "        batch_size = input_shape[0]  # 배치 크기\n",
    "        height = input_shape[1]  # 이미지 높이\n",
    "        width = input_shape[2]  # 이미지 너비\n",
    "        channels = input_shape[3]  # 채널 수 (RGB의 경우 3)\n",
    "        num_patches_h = height // self.patch_size  # 높이 방향 패치 개수\n",
    "        num_patches_w = width // self.patch_size  # 너비 방향 패치 개수\n",
    "        # 이미지를 작은 패치들로 분할\n",
    "        patches = keras.ops.image.extract_patches(images, size=self.patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패치를 (배치 크기, 패치 개수, 패치 벡터 크기) 형태로 변환\n",
    "        patches = ops.reshape(\n",
    "            patches,\n",
    "            (\n",
    "                batch_size,\n",
    "                num_patches_h * num_patches_w,  # 전체 패치 개수\n",
    "                self.patch_size * self.patch_size * channels,  # 패치를 벡터로 변환\n",
    "            ),\n",
    "        )\n",
    "        return patches  # 변환된 패치 반환\n",
    "    def get_config(self):  # 모델 저장 및 불러오기를 위한 설정 반환\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})  # 패치 크기 정보 추가\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659442b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))  # 4x4 크기의 그림(플롯) 생성\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]  # 학습 데이터에서 랜덤한 이미지 선택\n",
    "plt.imshow(image.astype(\"uint8\"))  # 선택한 이미지를 화면에 표시\n",
    "plt.axis(\"off\")  # 축 제거 (불필요한 테두리 없앰)\n",
    "# 선택한 이미지를 지정된 크기로 리사이징\n",
    "resized_image = ops.image.resize(\n",
    "    ops.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "# 리사이징된 이미지에서 패치 생성\n",
    "patches = Patches(patch_size)(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패치 관련 정보 출력\n",
    "print(f\"Image size: {image_size} X {image_size}\")  # 이미지 크기 출력\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")  # 패치 크기 출력\n",
    "print(f\"Patches per image: {patches.shape[1]}\")  # 한 이미지에서 생성된 패치 개수 출력\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")  # 각 패치가 가진 요소 개수 출력\n",
    "\n",
    "# 패치를 시각적으로 확인\n",
    "n = int(np.sqrt(patches.shape[1]))  # 패치 개수의 제곱근 계산 (정사각형 형태로 출력하기 위함)\n",
    "plt.figure(figsize=(4, 4))  # 4x4 크기의 플롯 생성\n",
    "for i, patch in enumerate(patches[0]):  # 첫 번째 이미지의 패치들을 반복하면서 출력\n",
    "    ax = plt.subplot(n, n, i + 1)  # n x n 서브플롯 생성\n",
    "    patch_img = ops.reshape(patch, (patch_size, patch_size, 3))  # 패치를 원래 이미지 형태로 변환\n",
    "    plt.imshow(ops.convert_to_numpy(patch_img).astype(\"uint8\"))  # 패치를 시각화\n",
    "    plt.axis(\"off\")  # 축 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03736c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):  # 패치 인코딩을 위한 커스텀 Keras 레이어\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches  # 전체 패치 개수 저장\n",
    "        self.projection = layers.Dense(units=projection_dim)  # 패치를 특정 차원으로 변환하는 완전 연결(Dense) 레이어\n",
    "        self.position_embedding = layers.Embedding(  # 위치 임베딩을 위한 Embedding 레이어\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "    def call(self, patch):\n",
    "        # 패치의 위치 인덱스 생성 (0부터 num_patches-1까지)\n",
    "        positions = ops.expand_dims(\n",
    "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 패치를 projection_dim 차원으로 변환 (선형 변환)\n",
    "        projected_patches = self.projection(patch)\n",
    "        \n",
    "        # 위치 임베딩을 추가하여 패치의 위치 정보를 인코딩\n",
    "        encoded = projected_patches + self.position_embedding(positions)\n",
    "        \n",
    "        return encoded  # 인코딩된 패치 반환\n",
    "    def get_config(self):  # 모델 저장 및 불러오기를 위한 설정 반환\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})  # 패치 개수 정보 추가\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():  # Vision Transformer(ViT) 분류 모델 생성 함수\n",
    "    inputs = keras.Input(shape=input_shape)  # 입력층 정의 (이미지 크기: input_shape)\n",
    "    \n",
    "    # 데이터 증강 (Data Augmentation) 적용\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    # 이미지를 작은 패치(Patch)로 분할\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    \n",
    "    # 패치를 Transformer가 처리할 수 있도록 인코딩 (Patch Embedding + Position Encoding)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for _ in range(transformer_layers):\n",
    "        # Layer Normalization 1\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        \n",
    "        # Multi-Head Self-Attention 레이어 생성\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        \n",
    "        # Skip Connection 1 (잔차 연결)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        \n",
    "        # Layer Normalization 2\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        \n",
    "        # MLP (Feed Forward Network) 추가\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        \n",
    "        # Skip Connection 2 (잔차 연결)\n",
    "        encoded_patches = layers.Add()([x3, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 특징 벡터 생성 (Batch 크기 × projection_dim 형태의 텐서)\n",
    "\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)  # Flatten하여 1D 벡터로 변환\n",
    "    representation = layers.Dropout(0.5)(representation)  # 과적합 방지를 위한 Dropout\n",
    "    \n",
    "    # MLP 헤드 추가 (Fully Connected Layer)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    \n",
    "    # 최종 분류 레이어 (num_classes 개의 클래스 출력)\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    \n",
    "    # Keras 모델 생성\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model  # 모델 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def run_experiment(model):  # 모델 학습 및 평가를 수행하는 함수\n",
    "        \n",
    "    # AdamW 옵티마이저 설정 (Adam + Weight Decay 적용)\n",
    "    optimizer = keras.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    # 모델 컴파일 (손실 함수 및 평가 지표 설정)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,  # AdamW 옵티마이저 사용\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # 다중 클래스 분류를 위한 손실 함수\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),  # 정확도(Accuracy)\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),  \n",
    "\t    # Top-5 정확도 (상위 5개 중 정답 포함 여부)\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # 체크포인트(최적 모델 저장) 파일 경로 설정\n",
    "    checkpoint_filepath = \"/content/drive/MyDrive/Colab/checkpoint.weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27888b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # 체크포인트 콜백 설정 (최고 성능 모델 저장)\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,  # 저장 위치\n",
    "        monitor=\"val_accuracy\",  # 검증 데이터 정확도 기준으로 저장\n",
    "        save_best_only=True,  # 최고 성능 모델만 저장\n",
    "        save_weights_only=True,  # 가중치만 저장 (전체 모델 저장 X)\n",
    "    )\n",
    "    \n",
    "    # 모델 학습 (훈련 데이터에서 10%를 검증 데이터로 사용)\n",
    "    history = model.fit(\n",
    "        x=x_train,  # 학습 데이터 (입력 이미지)\n",
    "        y=y_train,  # 학습 데이터 (정답 레이블)\n",
    "        batch_size=batch_size,  # 배치 크기 설정\n",
    "        epochs=num_epochs,  # 학습 반복 횟수\n",
    "        validation_split=0.1,  # 학습 데이터 중 10%를 검증 데이터로 사용\n",
    "        callbacks=[checkpoint_callback],  # 체크포인트 콜백 적용\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 가중치 중 최적 성능 모델 불러오기\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    \n",
    "    # 테스트 데이터에서 모델 성능 평가\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    # 테스트 정확도 출력\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "    return history  # 학습 기록 반환\n",
    "\n",
    "# Vision Transformer(ViT) 모델 생성\n",
    "vit_classifier = create_vit_classifier()\n",
    "\n",
    "# ViT 모델 학습 및 평가 실행\n",
    "history = run_experiment(vit_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d57300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 시각화 함수 정의\n",
    "def plot_history(item):\n",
    "    plt.plot(history.history[item], label=item)  # 학습 데이터의 손실 또는 정확도 그래프\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)  # 검증 데이터의 손실 또는 정확도 그래프\n",
    "    plt.xlabel(\"Epochs\")  # x축: 에포크(Epochs)\n",
    "    plt.ylabel(item)  # y축: 손실(Loss) 또는 정확도(Accuracy)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)  # 그래프 제목 설정\n",
    "    plt.legend()  # 범례 추가\n",
    "    plt.grid()  # 격자 표시\n",
    "    plt.show()  # 그래프 출력\n",
    "    \n",
    "# 학습 손실 그래프 출력\n",
    "plot_history(\"loss\")\n",
    "\n",
    "# Top-5 정확도 그래프 출력\n",
    "plot_history(\"top-5-accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

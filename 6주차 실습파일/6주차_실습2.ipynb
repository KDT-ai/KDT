{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa0e84c",
   "metadata": {},
   "source": [
    "Deep Convolutional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from google.colab import drive\n",
    "from torchvision.datasets import ImageFolder\n",
    "from google.colab import files\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 장치: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08095f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_size = 64\n",
    "nz = 100  \n",
    "ngf = 64  \n",
    "ndf = 64  \n",
    "num_epochs = 25  # 명확한 이미지를 원할 경우 epochs를 늘리기\n",
    "lr = 0.0002\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018679e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dog_dataset():\n",
    "    print(\"강아지 데이터셋 다운로드 중...\")\n",
    "    import torchvision.datasets as datasets\n",
    "\n",
    "    cifar10 = datasets.CIFAR10(root='./cifar10', download=True, train=True)\n",
    "    \n",
    "    class_labels = cifar10.classes  \n",
    "    print(f\"CIFAR-10 클래스 목록: {class_labels}\")\n",
    "\n",
    "    dog_idx = class_labels.index('dog')  \n",
    "    print(f\"강아지 클래스 인덱스: {dog_idx}\")\n",
    "    dog_images = []\n",
    "    \n",
    "    for i in range(len(cifar10)):\n",
    "        img, label = cifar10[i]\n",
    "        if label == dog_idx:\n",
    "            dog_images.append(img)\n",
    "    print(f\"{len(dog_images)}개의 강아지 이미지를 추출했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 폴더 생성\n",
    "    os.makedirs('./dog_dataset/dogs', exist_ok=True)\n",
    "    # 이미지 저장\n",
    "    for i, img in enumerate(dog_images):\n",
    "        img.save(f'./dog_dataset/dogs/dog_{i}.jpg')\n",
    "    print(f\"이미지를 './dog_dataset/dogs/' 폴더에 저장했습니다.\")\n",
    "    return './dog_dataset’  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not os.path.exists('./dog_dataset') or len(glob.glob('./dog_dataset/*/*.jpg')) == 0:\n",
    "        data_root = download_dog_dataset()\n",
    "    else:\n",
    "        data_root = './dog_dataset'\n",
    "        print(f\"기존 데이터셋 사용: {data_root}\")\n",
    "except:\n",
    "    print(\"데이터셋 확인 중 오류 발생 확인, 재다운로드를 시도합니다.\")\n",
    "    data_root = download_dog_dataset()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = ImageFolder(root=data_root, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    print(f\"데이터셋 로드 완료: {len(dataset)} 이미지\")\n",
    "except Exception as e:\n",
    "    print(f\"데이터셋 로드 오류: {e}\")\n",
    "    print(\"임의 데이터로 코드를 계속 실행합니다...\")\n",
    "    \n",
    "    def create_random_dataset(num_samples=1000):\n",
    "        random_data = torch.randn(num_samples, 3, image_size, image_size)\n",
    "        random_data = torch.clamp((random_data * 0.2) + 0.5, 0, 1) \n",
    "        random_dataset = [(img, 0) for img in random_data] \n",
    "        return random_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx]\n",
    "    \n",
    "    random_dataset = RandomDataset(create_random_dataset())\n",
    "    dataloader = DataLoader(random_dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(f\"임의의 데이터셋 생성 완료: {len(random_dataset)} 이미지\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9091c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\u000b\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3652141",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(\"생성자 모델 구조:\")\n",
    "print(netG)\n",
    "print(\"\\n판별자 모델 구조:\")\n",
    "print(netD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5243f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(images, title=None, display_in_notebook=True):\n",
    "    images = (images + 1) / 2.0\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(images, padding=2, normalize=False)\n",
    "    img = grid.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if display_in_notebook:\n",
    "        plt.show()\n",
    "    return img\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568920ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"학습 시작...\")\n",
    "def progress_bar(current, total, bar_length=50):\n",
    "    fraction = current / total\n",
    "    arrow = int(fraction * bar_length) * '='\n",
    "    padding = (bar_length - len(arrow)) * ' '\n",
    "    return f\"[{arrow}{padding}] {int(fraction * 100)}%\"\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(dataloader, 0):        \n",
    "       \n",
    "        netD.zero_grad()\n",
    "        if isinstance(data, list) and len(data) == 2:  \n",
    "            real_cpu = data[0].to(device)\n",
    "        else:  \n",
    "            real_cpu = data[0].to(device)\n",
    "            \n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        \n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.zero_grad()\n",
    "        label.fill_(real_label)  \n",
    "        \n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        \n",
    "        optimizerG.step()\n",
    "        \n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            prog = progress_bar(i, len(dataloader))\n",
    "            print(f'\\r에폭 [{epoch+1}/{num_epochs}] 배치 {prog} '\n",
    "                  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n",
    "                  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f}/{D_G_z2:.4f}', end='')\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        fake = netG(fixed_noise).detach().cpu()\n",
    "    img_list.append(fake)\n",
    "    \n",
    "      img = visualize_images(fake, title=f'에폭 {epoch+1} 생성 결과')\n",
    "    \n",
    "    plt.savefig(f'results/fake_dogs_epoch_{epoch+1}.png')\n",
    "    plt.close()\n",
    "    \n",
    "      if (epoch + 1) % 5 == 0 or (epoch + 1) == num_epochs:\n",
    "        torch.save({\n",
    "            'generator': netG.state_dict(),\n",
    "            'discriminator': netD.state_dict(),\n",
    "            'optimizerG': optimizerG.state_dict(),\n",
    "            'optimizerD': optimizerD.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'G_losses': G_losses,\n",
    "            'D_losses': D_losses,\n",
    "        }, f'checkpoints/gan_model_epoch_{epoch+1}.pth')\n",
    "        print(f\"모델 체크포인트 저장: 에폭 {epoch+1}\")\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f'에폭 {epoch+1} 완료, 소요 시간: {elapsed:.2f}초')\n",
    "print(\"학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ebd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"생성자와 판별자의 손실\")\n",
    "plt.plot(G_losses, label=\"생성자\")\n",
    "plt.plot(D_losses, label=\"판별자\")\n",
    "plt.xlabel(\"반복\")\n",
    "plt.ylabel(\"손실\")\n",
    "plt.legend()\n",
    "plt.savefig('results/loss_plot.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "rows = int(np.sqrt(num_epochs))\n",
    "cols = int(np.ceil(num_epochs / rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(num_epochs, len(img_list))):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'에폭 {i+1}')\n",
    "    \n",
    "    if i < len(img_list):\n",
    "        img = torchvision.utils.make_grid(img_list[i][:16], padding=2, normalize=True)\n",
    "        plt.imshow(np.transpose(img.cpu().numpy(), (1, 2, 0)))\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('results/progress.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58939b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_dogs(num_images=16):\n",
    "    netG.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_images, nz, 1, 1, device=device)\n",
    "        \n",
    "        fake_dogs = netG(noise).detach().cpu()\n",
    "        \n",
    "        visualize_images(fake_dogs, title=f'생성된 강아지 이미지 {num_images}개')\n",
    "        plt.savefig('results/final_generated_dogs.png')\n",
    "        \n",
    "        print(f\"{num_images}개의 새로운 강아지 이미지를 생성했습니다. ('results/final_generated_dogs.png'에 저장)\")\n",
    "        \n",
    "        return fake_dogs\n",
    "\n",
    "print(\"\\n최종 모델로 새 이미지 생성:\")\n",
    "generate_new_dogs(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed0b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_results():\n",
    "    print(\"\\n생성된 결과 다운로드:\")\n",
    "    print(\"1. 왼쪽 사이드바에서 파일 탭(📁)을 클릭합니다.\")\n",
    "    print(\"2. 'results' 폴더에서 생성된 이미지를 다운로드합니다.\")\n",
    "    print(\"또는 아래 코드를 실행하여 결과 파일을 다운로드할 수 있습니다:\")\n",
    "    print(\"files.download('results/final_generated_dogs.png')\")\n",
    "    print(\"files.download('results/progress.png')\")\n",
    "    print(\"files.download('results/loss_plot.png')\")\n",
    "print(\"\\n=== GAN 실습 완료 ===\")\n",
    "print(\"생성된 모든 결과는 'results' 폴더에 저장되었습니다.\")\n",
    "download_results()`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

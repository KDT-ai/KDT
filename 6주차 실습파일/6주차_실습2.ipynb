{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa0e84c",
   "metadata": {},
   "source": [
    "Deep Convolutional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedc9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from google.colab import drive\n",
    "from torchvision.datasets import ImageFolder\n",
    "from google.colab import files\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "Â  Â  random.seed(seed)\n",
    "Â  Â  np.random.seed(seed)\n",
    "Â  Â  torch.manual_seed(seed)\n",
    "Â  Â  if torch.cuda.is_available():\n",
    "Â  Â  Â  Â  torch.cuda.manual_seed_all(seed)\n",
    "Â  Â  Â  Â  torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ì‚¬ìš© ì¥ì¹˜: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08095f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_size = 64\n",
    "nz = 100 Â \n",
    "ngf = 64 Â \n",
    "ndf = 64 Â \n",
    "num_epochs = 25 Â # ëª…í™•í•œ ì´ë¯¸ì§€ë¥¼ ì›í•  ê²½ìš° epochsë¥¼ ëŠ˜ë¦¬ê¸°\n",
    "lr = 0.0002\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018679e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dog_dataset():\n",
    "Â  Â  print(\"ê°•ì•„ì§€ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "Â  Â  import torchvision.datasets as datasets\n",
    "\n",
    "Â  Â  cifar10 = datasets.CIFAR10(root='./cifar10', download=True, train=True)\n",
    "Â  Â  \n",
    "Â  Â  class_labels = cifar10.classes Â \n",
    "Â  Â  print(f\"CIFAR-10 í´ë˜ìŠ¤ ëª©ë¡: {class_labels}\")\n",
    "\n",
    "Â  Â  dog_idx = class_labels.index('dog') Â \n",
    "Â  Â  print(f\"ê°•ì•„ì§€ í´ë˜ìŠ¤ ì¸ë±ìŠ¤: {dog_idx}\")\n",
    "Â  Â  dog_images = []\n",
    "Â  Â  \n",
    "Â  Â  for i in range(len(cifar10)):\n",
    "Â  Â  Â  Â  img, label = cifar10[i]\n",
    "Â  Â  Â  Â  if label == dog_idx:\n",
    "Â  Â  Â  Â  Â  Â  dog_images.append(img)\n",
    "Â  Â  print(f\"{len(dog_images)}ê°œì˜ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥ í´ë” ìƒì„±\n",
    "Â  Â  os.makedirs('./dog_dataset/dogs', exist_ok=True)\n",
    "Â  Â  # ì´ë¯¸ì§€ ì €ì¥\n",
    "Â  Â  for i, img in enumerate(dog_images):\n",
    "Â  Â  Â  Â  img.save(f'./dog_dataset/dogs/dog_{i}.jpg')\n",
    "Â  Â  print(f\"ì´ë¯¸ì§€ë¥¼ './dog_dataset/dogs/' í´ë”ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "Â  Â  return './dog_datasetâ€™ Â \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca6aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "Â  Â  if not os.path.exists('./dog_dataset') or len(glob.glob('./dog_dataset/*/*.jpg')) == 0:\n",
    "Â  Â  Â  Â  data_root = download_dog_dataset()\n",
    "Â  Â  else:\n",
    "Â  Â  Â  Â  data_root = './dog_dataset'\n",
    "Â  Â  Â  Â  print(f\"ê¸°ì¡´ ë°ì´í„°ì…‹ ì‚¬ìš©: {data_root}\")\n",
    "except:\n",
    "Â  Â  print(\"ë°ì´í„°ì…‹ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ í™•ì¸, ì¬ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.\")\n",
    "Â  Â  data_root = download_dog_dataset()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "Â  Â  transforms.Resize(image_size),\n",
    "Â  Â  transforms.CenterCrop(image_size),\n",
    "Â  Â  transforms.ToTensor(),\n",
    "Â  Â  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "Â  Â  dataset = ImageFolder(root=data_root, transform=transform)\n",
    "Â  Â  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "Â  Â  print(f\"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(dataset)} ì´ë¯¸ì§€\")\n",
    "except Exception as e:\n",
    "Â  Â  print(f\"ë°ì´í„°ì…‹ ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
    "Â  Â  print(\"ì„ì˜ ë°ì´í„°ë¡œ ì½”ë“œë¥¼ ê³„ì† ì‹¤í–‰í•©ë‹ˆë‹¤...\")\n",
    "Â  Â  \n",
    "Â  Â  def create_random_dataset(num_samples=1000):\n",
    "Â  Â  Â  Â  random_data = torch.randn(num_samples, 3, image_size, image_size)\n",
    "Â  Â  Â  Â  random_data = torch.clamp((random_data * 0.2) + 0.5, 0, 1) \n",
    "Â  Â  Â  Â  random_dataset = [(img, 0) for img in random_data] \n",
    "Â  Â  Â  Â  return random_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(torch.utils.data.Dataset):\n",
    "Â  Â  Â  Â  def __init__(self, data):\n",
    "Â  Â  Â  Â  Â  Â  self.data = data\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  def __len__(self):\n",
    "Â  Â  Â  Â  Â  Â  return len(self.data)\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  def __getitem__(self, idx):\n",
    "Â  Â  Â  Â  Â  Â  return self.data[idx]\n",
    "Â  Â  \n",
    "Â  Â  random_dataset = RandomDataset(create_random_dataset())\n",
    "Â  Â  dataloader = DataLoader(random_dataset, batch_size=batch_size, shuffle=True)\n",
    "Â  Â  print(f\"ì„ì˜ì˜ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {len(random_dataset)} ì´ë¯¸ì§€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "Â  Â  classname = m.__class__.__name__\n",
    "Â  Â  if classname.find('Conv') != -1:\n",
    "Â  Â  Â  Â  nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "Â  Â  elif classname.find('BatchNorm') != -1:\n",
    "Â  Â  Â  Â  nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "Â  Â  Â  Â  nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9091c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "Â  Â  def __init__(self):\n",
    "Â  Â  Â  Â  super(Generator, self).__init__()\n",
    "Â  Â  Â  Â  self.main = nn.Sequential(\n",
    "Â  Â  Â  Â  Â  Â  nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.BatchNorm2d(ngf * 8),\n",
    "Â  Â  Â  Â  Â  Â  nn.ReLU(True),\n",
    "Â  Â  Â  Â  Â  Â  nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.BatchNorm2d(ngf * 4),\n",
    "Â  Â  Â  Â  Â  Â  nn.ReLU(True),\n",
    "Â  Â  Â  Â  Â  Â  nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.BatchNorm2d(ngf * 2),\n",
    "Â  Â  Â  Â  Â  Â  nn.ReLU(True),\n",
    "Â  Â  Â  Â  Â  Â  nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.BatchNorm2d(ngf),\n",
    "Â  Â  Â  Â  Â  Â  nn.ReLU(True),\n",
    "Â  Â  Â  Â  Â  Â  nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.Tanh()\n",
    "Â  Â  Â  Â  )\u000b\n",
    "Â  Â  def forward(self, input):\n",
    "Â  Â  Â  Â  return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "Â  Â  def __init__(self):\n",
    "Â  Â  Â  Â  super(Discriminator, self).__init__()\n",
    "Â  Â  Â  Â  self.main = nn.Sequential(\n",
    "Â  Â  Â  Â  Â  Â  nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.LeakyReLU(0.2, inplace=True),\n",
    "Â  Â  Â  Â  Â  Â  nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.BatchNorm2d(ndf * 2),\n",
    "Â  Â  Â  Â  Â  Â  nn.LeakyReLU(0.2, inplace=True),\n",
    "Â  Â  Â  Â  Â  Â  nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.BatchNorm2d(ndf * 4),\n",
    "Â  Â  Â  Â  Â  Â  nn.LeakyReLU(0.2, inplace=True),\n",
    "Â  Â  Â  Â  Â  Â  nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.BatchNorm2d(ndf * 8),\n",
    "Â  Â  Â  Â  Â  Â  nn.LeakyReLU(0.2, inplace=True),\n",
    "Â  Â  Â  Â  Â  Â  nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "Â  Â  Â  Â  Â  Â  nn.Sigmoid()\n",
    "Â  Â  Â  Â  )\n",
    "Â  Â  def forward(self, input):\n",
    "Â  Â  Â  Â  return self.main(input).view(-1, 1).squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3652141",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "print(\"ìƒì„±ì ëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(netG)\n",
    "print(\"\\níŒë³„ì ëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(netD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5243f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(images, title=None, display_in_notebook=True):\n",
    "Â  Â  images = (images + 1) / 2.0\n",
    "Â  Â  \n",
    "Â  Â  grid = torchvision.utils.make_grid(images, padding=2, normalize=False)\n",
    "Â  Â  img = grid.permute(1, 2, 0).cpu().numpy()\n",
    "Â  Â  \n",
    "Â  Â  plt.figure(figsize=(8, 8))\n",
    "Â  Â  plt.imshow(img)\n",
    "Â  Â  if title:\n",
    "Â  Â  Â  Â  plt.title(title)\n",
    "Â  Â  plt.axis('off')\n",
    "Â  Â  \n",
    "Â  Â  if display_in_notebook:\n",
    "Â  Â  Â  Â  plt.show()\n",
    "Â  Â  return img\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568920ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"í•™ìŠµ ì‹œì‘...\")\n",
    "def progress_bar(current, total, bar_length=50):\n",
    "Â  Â  fraction = current / total\n",
    "Â  Â  arrow = int(fraction * bar_length) * '='\n",
    "Â  Â  padding = (bar_length - len(arrow)) * ' '\n",
    "Â  Â  return f\"[{arrow}{padding}] {int(fraction * 100)}%\"\n",
    "for epoch in range(num_epochs):\n",
    "Â  Â  start_time = time.time()\n",
    "Â  Â  for i, data in enumerate(dataloader, 0):Â  Â  Â  Â  \n",
    "Â  Â  Â  Â \n",
    "Â  Â  Â  Â  netD.zero_grad()\n",
    "Â  Â  Â  Â  if isinstance(data, list) and len(data) == 2: Â \n",
    "Â  Â  Â  Â  Â  Â  real_cpu = data[0].to(device)\n",
    "Â  Â  Â  Â  else: Â \n",
    "Â  Â  Â  Â  Â  Â  real_cpu = data[0].to(device)\n",
    "Â  Â  Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  batch_size = real_cpu.size(0)\n",
    "Â  Â  Â  Â  label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = netD(real_cpu)\n",
    "Â  Â  Â  Â  errD_real = criterion(output, label)\n",
    "Â  Â  Â  Â  errD_real.backward()\n",
    "Â  Â  Â  Â  D_x = output.mean().item()\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "Â  Â  Â  Â  fake = netG(noise)\n",
    "Â  Â  Â  Â  label.fill_(fake_label)\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  output = netD(fake.detach())\n",
    "Â  Â  Â  Â  errD_fake = criterion(output, label)\n",
    "Â  Â  Â  Â  errD_fake.backward()\n",
    "Â  Â  Â  Â  D_G_z1 = output.mean().item()\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  errD = errD_real + errD_fake\n",
    "Â  Â  Â  Â  optimizerD.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.zero_grad()\n",
    "Â  Â  Â  Â  label.fill_(real_label) Â \n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  output = netD(fake)\n",
    "Â  Â  Â  Â  errG = criterion(output, label)\n",
    "Â  Â  Â  Â  errG.backward()\n",
    "Â  Â  Â  Â  D_G_z2 = output.mean().item()\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  optimizerG.step()\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  G_losses.append(errG.item())\n",
    "Â  Â  Â  Â  D_losses.append(errD.item())\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  if i % 10 == 0:\n",
    "Â  Â  Â  Â  Â  Â  prog = progress_bar(i, len(dataloader))\n",
    "Â  Â  Â  Â  Â  Â  print(f'\\rì—í­ [{epoch+1}/{num_epochs}] ë°°ì¹˜ {prog} '\n",
    "Â  Â  Â  Â  Â  Â  Â  Â  Â  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n",
    "Â  Â  Â  Â  Â  Â  Â  Â  Â  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f}/{D_G_z2:.4f}', end='')\n",
    "Â  Â  \n",
    "Â  Â  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "Â  Â  Â  Â  fake = netG(fixed_noise).detach().cpu()\n",
    "Â  Â  img_list.append(fake)\n",
    "Â  Â  \n",
    "Â  Â  Â  img = visualize_images(fake, title=f'ì—í­ {epoch+1} ìƒì„± ê²°ê³¼')\n",
    "Â  Â  \n",
    "Â  Â  plt.savefig(f'results/fake_dogs_epoch_{epoch+1}.png')\n",
    "Â  Â  plt.close()\n",
    "Â  Â  \n",
    "Â  Â  Â  if (epoch + 1) % 5 == 0 or (epoch + 1) == num_epochs:\n",
    "Â  Â  Â  Â  torch.save({\n",
    "Â  Â  Â  Â  Â  Â  'generator': netG.state_dict(),\n",
    "Â  Â  Â  Â  Â  Â  'discriminator': netD.state_dict(),\n",
    "Â  Â  Â  Â  Â  Â  'optimizerG': optimizerG.state_dict(),\n",
    "Â  Â  Â  Â  Â  Â  'optimizerD': optimizerD.state_dict(),\n",
    "Â  Â  Â  Â  Â  Â  'epoch': epoch,\n",
    "Â  Â  Â  Â  Â  Â  'G_losses': G_losses,\n",
    "Â  Â  Â  Â  Â  Â  'D_losses': D_losses,\n",
    "Â  Â  Â  Â  }, f'checkpoints/gan_model_epoch_{epoch+1}.pth')\n",
    "Â  Â  Â  Â  print(f\"ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: ì—í­ {epoch+1}\")\n",
    "Â  Â  elapsed = time.time() - start_time\n",
    "Â  Â  print(f'ì—í­ {epoch+1} ì™„ë£Œ, ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ')\n",
    "print(\"í•™ìŠµ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ebd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"ìƒì„±ìì™€ íŒë³„ìì˜ ì†ì‹¤\")\n",
    "plt.plot(G_losses, label=\"ìƒì„±ì\")\n",
    "plt.plot(D_losses, label=\"íŒë³„ì\")\n",
    "plt.xlabel(\"ë°˜ë³µ\")\n",
    "plt.ylabel(\"ì†ì‹¤\")\n",
    "plt.legend()\n",
    "plt.savefig('results/loss_plot.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "rows = int(np.sqrt(num_epochs))\n",
    "cols = int(np.ceil(num_epochs / rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(num_epochs, len(img_list))):\n",
    "Â  Â  plt.subplot(rows, cols, i + 1)\n",
    "Â  Â  plt.axis('off')\n",
    "Â  Â  plt.title(f'ì—í­ {i+1}')\n",
    "Â  Â  \n",
    "Â  Â  if i < len(img_list):\n",
    "Â  Â  Â  Â  img = torchvision.utils.make_grid(img_list[i][:16], padding=2, normalize=True)\n",
    "Â  Â  Â  Â  plt.imshow(np.transpose(img.cpu().numpy(), (1, 2, 0)))\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('results/progress.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58939b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_dogs(num_images=16):\n",
    "Â  Â  netG.eval()\n",
    "Â  Â  \n",
    "Â  Â  with torch.no_grad():\n",
    "Â  Â  Â  Â  noise = torch.randn(num_images, nz, 1, 1, device=device)\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  fake_dogs = netG(noise).detach().cpu()\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  visualize_images(fake_dogs, title=f'ìƒì„±ëœ ê°•ì•„ì§€ ì´ë¯¸ì§€ {num_images}ê°œ')\n",
    "Â  Â  Â  Â  plt.savefig('results/final_generated_dogs.png')\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  print(f\"{num_images}ê°œì˜ ìƒˆë¡œìš´ ê°•ì•„ì§€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ('results/final_generated_dogs.png'ì— ì €ì¥)\")\n",
    "Â  Â  Â  Â  \n",
    "Â  Â  Â  Â  return fake_dogs\n",
    "\n",
    "print(\"\\nìµœì¢… ëª¨ë¸ë¡œ ìƒˆ ì´ë¯¸ì§€ ìƒì„±:\")\n",
    "generate_new_dogs(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed0b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_results():\n",
    "Â  Â  print(\"\\nìƒì„±ëœ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ:\")\n",
    "Â  Â  print(\"1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ íƒ­(ğŸ“)ì„ í´ë¦­í•©ë‹ˆë‹¤.\")\n",
    "Â  Â  print(\"2. 'results' í´ë”ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
    "Â  Â  print(\"ë˜ëŠ” ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "Â  Â  print(\"files.download('results/final_generated_dogs.png')\")\n",
    "Â  Â  print(\"files.download('results/progress.png')\")\n",
    "Â  Â  print(\"files.download('results/loss_plot.png')\")\n",
    "print(\"\\n=== GAN ì‹¤ìŠµ ì™„ë£Œ ===\")\n",
    "print(\"ìƒì„±ëœ ëª¨ë“  ê²°ê³¼ëŠ” 'results' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "download_results()`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
